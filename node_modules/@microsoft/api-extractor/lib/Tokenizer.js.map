{"version":3,"sources":["Tokenizer.ts"],"names":[],"mappings":";AAAA,iCAA2C;AAC3C,yDAAoD;AAEpD;;GAEG;AACH;IAeE,mBAAY,IAAY,EAAE,WAAsC;QAC9D,IAAI,CAAC,YAAY,GAAG,WAAW,CAAC;QAChC,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;IAC/C,CAAC;IAED;;;;;;;;;;;OAWG;IACO,iCAAa,GAAvB,UAAwB,IAAY;QAClC,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC;YACV,MAAM,CAAC;QACT,CAAC;QACD,IAAM,UAAU,GAAa,2BAAiB,CAAC,oBAAoB,CAAC,IAAI,EAAE,SAAS,CAAC,eAAe,CAAC,CAAC;QACrG,IAAM,eAAe,GAAc,IAAI,CAAC,mBAAmB,CAAC,UAAU,CAAC,CAAC,CAAC,uCAAuC;QAEhH,sDAAsD;QACtD,IAAM,MAAM,GAAY,EAAE,CAAC;QAC3B,IAAI,KAAa,CAAC;QAClB,GAAG,CAAC,CAAC,IAAI,CAAC,GAAW,CAAC,EAAE,CAAC,GAAG,eAAe,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACxD,IAAI,KAAK,SAAO,CAAC;YACjB,KAAK,GAAG,eAAe,CAAC,CAAC,CAAC,CAAC;YAC3B,EAAE,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;gBAC7B,KAAK,GAAG,IAAI,eAAK,CAAC,iBAAS,CAAC,GAAG,EAAE,KAAK,CAAC,CAAC;YACzC,CAAC;YAAC,IAAI,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,GAAG,IAAI,KAAK,CAAC,MAAM,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;gBAC7E,KAAK,GAAG,IAAI,CAAC,eAAe,CAAC,KAAK,CAAC,CAAC,CAAC,6CAA6C;YACpF,CAAC;YAAC,IAAI,CAAC,CAAC;gBACN,KAAK,GAAG,IAAI,eAAK,CAAC,iBAAS,CAAC,IAAI,EAAE,EAAE,EAAE,KAAK,CAAC,CAAC;YAC/C,CAAC;YAED,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;gBACV,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YACrB,CAAC;QACH,CAAC;QAED,MAAM,CAAC,MAAM,CAAC;IAChB,CAAC;IAED;;;OAGG;IACO,mCAAe,GAAzB,UAA0B,QAAgB;QACxC,EAAE,CAAC,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,GAAG,IAAI,QAAQ,CAAC,MAAM,CAAC,QAAQ,CAAC,MAAM,GAAG,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;YAC/E,IAAI,CAAC,YAAY,CAAC,wDAAwD,CAAC,CAAC;YAC5E,MAAM,CAAC;QACT,CAAC;QACD,IAAM,YAAY,GAAW,QAAQ,CAAC,KAAK,CAAC,CAAC,EAAE,QAAQ,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QAE3E,EAAE,CAAC,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;YACnC,IAAI,CAAC,YAAY,CAAC,2DAA2D,CAAC,CAAC;YAC/E,MAAM,CAAC;QACT,CAAC;QAED,IAAM,oBAAoB,GAAW,oBAAoB,CAAC;QAC1D,EAAE,CAAC,CAAC,oBAAoB,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;YAC5C,IAAI,CAAC,YAAY,CAAC,sDAAsD;gBACtE,mDAAmD,CAAC,CAAC;YACvD,MAAM,CAAC;QACT,CAAC;QAED,+CAA+C;QAC/C,8FAA8F;QAC9F,IAAM,WAAW,GAAa,YAAY,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC;QAC1D,EAAE,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,KAAK,OAAO,CAAC,CAAC,CAAC;YAC/B,EAAE,CAAC,CAAC,WAAW,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC;gBAC3B,IAAI,CAAC,YAAY,CAAC,0CAA0C,CAAC,CAAC;gBAC9D,MAAM,CAAC;YACT,CAAC;YAED,WAAW,CAAC,KAAK,EAAE,CAAC,CAAC,sBAAsB;YAC3C,IAAM,KAAK,GAAU,IAAI,eAAK,CAAC,iBAAS,CAAC,MAAM,EAAE,OAAO,EAAE,WAAW,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;YACjF,MAAM,CAAC,KAAK,CAAC;QACf,CAAC;QAAC,IAAI,CAAC,EAAE,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,KAAK,aAAa,CAAC,CAAC,CAAC;YAC5C,WAAW,CAAC,KAAK,EAAE,CAAC,CAAC,4BAA4B;YACjD,IAAM,KAAK,GAAU,IAAI,eAAK,CAAC,iBAAS,CAAC,MAAM,EAAE,aAAa,EAAE,WAAW,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;YACvF,MAAM,CAAC,KAAK,CAAC;QACf,CAAC;QAED,IAAI,CAAC,YAAY,CAAC,kCAAkC,CAAC,CAAC;QACtD,MAAM,CAAC;IACT,CAAC;IAEM,6BAAS,GAAhB;QACE,MAAM,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,YAAY,CAAC,MAAM,KAAK,CAAC,CAAC,GAAG,SAAS,GAAG,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;IACnG,CAAC;IAEM,4BAAQ,GAAf;QACE,MAAM,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,YAAY,CAAC,MAAM,KAAK,CAAC,CAAC,GAAG,SAAS,GAAG,IAAI,CAAC,YAAY,CAAC,KAAK,EAAE,CAAC;IACxG,CAAC;IAED;;;;;OAKG;IACK,uCAAmB,GAA3B,UAA4B,UAAoB;QAC9C,IAAM,MAAM,GAAa,EAAE,CAAC;QAC5B,GAAG,CAAC,CAAc,UAAU,EAAV,yBAAU,EAAV,wBAAU,EAAV,IAAU;YAAvB,IAAI,KAAK,mBAAA;YACZ,KAAK,GAAG,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE,GAAG,CAAC,CAAC;YACnC,KAAK,GAAG,KAAK,CAAC,IAAI,EAAE,CAAC;YAErB,EAAE,CAAC,CAAC,KAAK,KAAK,EAAE,CAAC,CAAC,CAAC;gBACjB,QAAQ,CAAC;YACX,CAAC;YACD,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SACpB;QAED,MAAM,CAAC,MAAM,CAAC;IAChB,CAAC;IACH,gBAAC;AAAD,CAtIA,AAsIC;AApIC;;;GAGG;AACY,yBAAe,GAAW,sDAAsD,CAAC","file":"Tokenizer.js","sourcesContent":["import Token, { TokenType } from './Token';\r\nimport TypeScriptHelpers from './TypeScriptHelpers';\r\n\r\n/**\r\n * Handles the tokenization of a JSDoc comment.\r\n */\r\nexport default class Tokenizer {\r\n\r\n  /**\r\n   * Match JsDoc block tags and inline tags\r\n   * Example \"@a @b@c d@e @f {whatever} {@link a} { @something } \\@g\" => [\"@a\", \"@f\", \"{@link a}\", \"{ @something }\"]\r\n   */\r\n  private static _jsdocTagsRegex: RegExp = /{\\s*@(\\\\{|\\\\}|[^{}])*}|(?:^|\\s)(\\@[a-z_]+)(?=\\s|$)/gi;\r\n\r\n  /**\r\n   * List of Tokens that have been tokenized.\r\n   */\r\n  private _tokenStream: Token[];\r\n\r\n  private _reportError: (message: string) => void;\r\n\r\n  constructor(docs: string, reportError: (message: string) => void) {\r\n    this._reportError = reportError;\r\n    this._tokenStream = this._tokenizeDocs(docs);\r\n  }\r\n\r\n  /**\r\n   * Converts a doc comment string into an array of Tokens. This processing is done so that docs\r\n   * can be processed more strictly.\r\n   * Example: \"This is a JsDoc description with a {@link URL} and more text. \\@summary example \\@public\"\r\n   * => [\r\n   *  {tokenType: 'text', parameter: 'This is a JsDoc description with a'},\r\n   *  {tokenType: '@link', parameter: 'URL'},\r\n   *  {tokenType: '\\@summary', parameter: ''},\r\n   *  {tokenType: 'text', parameter: 'example'},\r\n   *  {tokenType: '\\@public', parameter: ''}\r\n   * ]\r\n   */\r\n  protected _tokenizeDocs(docs: string): Token[] {\r\n    if (!docs) {\r\n      return;\r\n    }\r\n    const docEntries: string[] = TypeScriptHelpers.splitStringWithRegEx(docs, Tokenizer._jsdocTagsRegex);\r\n    const sanitizedTokens: string[] =  this._sanitizeDocEntries(docEntries); // remove white space and empty entries\r\n\r\n    // process each sanitized doc string to a Token object\r\n    const tokens: Token[] = [];\r\n    let value: string;\r\n    for (let i: number = 0; i < sanitizedTokens.length; i++) {\r\n      let token: Token;\r\n      value = sanitizedTokens[i];\r\n      if (value.charAt(0) === '@') {\r\n       token = new Token(TokenType.Tag, value);\r\n      } else if (value.charAt(0) === '{' && value.charAt(value.length - 1) === '}') {\r\n        token = this._tokenizeInline(value); // Can return undefined if invalid inline tag\r\n      } else {\r\n        token = new Token(TokenType.Text, '', value);\r\n      }\r\n\r\n      if (token) {\r\n        tokens.push(token);\r\n      }\r\n    }\r\n\r\n    return tokens;\r\n  }\r\n\r\n  /**\r\n   * Parse an inline tag and returns the Token for it if itis a valid inline tag.\r\n   * Example '{@link https://bing.com | Bing}' => '{type: 'Inline', tag: '@link', text: 'https://bing.com  | Bing'}'\r\n   */\r\n  protected _tokenizeInline(docEntry: string): Token {\r\n    if (docEntry.charAt(0) !== '{' || docEntry.charAt(docEntry.length - 1) !== '}') {\r\n      this._reportError('All inline tags should be wrapped inside curly braces.');\r\n      return;\r\n    }\r\n    const tokenContent: string = docEntry.slice(1, docEntry.length - 1).trim();\r\n\r\n    if (tokenContent.charAt(0) !== '@') {\r\n      this._reportError('Content of inline tags should start with a leading \\'@\\'.');\r\n      return;\r\n    }\r\n\r\n    const unescapedCurlyBraces: RegExp = /([^\\\\])({|}[^$])/gi;\r\n    if (unescapedCurlyBraces.test(tokenContent)) {\r\n      this._reportError(`Unescaped '{' or '}' detected inside an inline tag. ` +\r\n        'Use \\\\ to escape curly braces inside inline tags.');\r\n      return;\r\n    }\r\n\r\n    // Split the inline tag content with whitespace\r\n    // Example: '@link    https://bing.com  |  Bing' => ['@link', 'https://bing.com', '|', 'Bing']\r\n    const tokenChunks: string[] = tokenContent.split(/\\s+/gi);\r\n    if (tokenChunks[0] === '@link') {\r\n      if (tokenChunks.length < 2) {\r\n        this._reportError('Too few parameters for @link inline tag.');\r\n        return;\r\n      }\r\n\r\n      tokenChunks.shift(); // Gets rid of '@link'\r\n      const token: Token = new Token(TokenType.Inline, '@link', tokenChunks.join(' '));\r\n      return token;\r\n    } else if (tokenChunks[0] === '@inheritdoc') {\r\n      tokenChunks.shift(); // Gets rid of '@inheritdoc'\r\n      const token: Token = new Token(TokenType.Inline, '@inheritdoc', tokenChunks.join(' '));\r\n      return token;\r\n    }\r\n\r\n    this._reportError('Unknown tag name for inline tag.');\r\n    return;\r\n  }\r\n\r\n  public peekToken(): Token {\r\n    return (!this._tokenStream || this._tokenStream.length === 0) ? undefined : this._tokenStream[0];\r\n  }\r\n\r\n  public getToken(): Token {\r\n    return (!this._tokenStream || this._tokenStream.length === 0) ? undefined : this._tokenStream.shift();\r\n  }\r\n\r\n  /**\r\n   * Trims whitespaces on either end of the entry (which is just a string within the doc comments),\r\n   * replaces \\r and \\n's with single whitespace, and removes empty entries.\r\n   *\r\n   * @param docEntries - Array of doc strings to be santitized\r\n   */\r\n  private _sanitizeDocEntries(docEntries: string[]): string[] {\r\n    const result: string[] = [];\r\n    for (let entry of docEntries) {\r\n      entry = entry.replace(/\\s+/g, ' ');\r\n      entry = entry.trim();\r\n\r\n      if (entry === '') {\r\n        continue;\r\n      }\r\n      result.push(entry);\r\n    }\r\n\r\n    return result;\r\n  }\r\n}\r\n"],"sourceRoot":"..\\src"}